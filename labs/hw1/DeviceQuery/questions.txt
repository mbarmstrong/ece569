1. What is the name of the GPU device used on the Ocelote?: Nvidia Tesla P100
2. What is the compute capability of this device?: 6.0
3. What are the shared, constant and global memory sizes for this device?: Shared: 64KB, constant: 64KB, global: 16GB
4. What is the maxim size of the block dimensions for this device?: 1024 
5. What is the compute capability of the NVIDIA Fermi architecture?: 2.0 - 2.1
6. What are the maximum block dimensions for GPUs with 5.0 compute capability?: 1024 x 1024 x 64
7. Suppose you are launching a one dimensional grid and block. If the hardware's maximum grid dimension is 65535 and the maximum block dimension is 512, what is the maximum number threads can be launched on the GPU?: 65535 blocks * 512 threads/block = 33,553,920 threads
8. Under what conditions might a programmer choose not to launch the maximum number of threads?: If the GPU does not have as many cores
9. What can limit a program from launching the maximum number of threads on a GPU?: Number of registers and shared memory available
10. What is shared memory?: Shared memory can be accessed by multiple threads in a block simultaneously, so that it is faster easier to share/pass data between threads without having redundant copies
11. What is global memory?: Global memory is the main memory on the GPU that can be accessed by all the blocks on the GPU, but is slower to access than shared memory
12. What is constant memory?: Constant memory is allocated by the host on the device and stores data that will not change during execution
13. What does warp size signify on a GPU?: Warp size is the number of threads that are executed at once
14. Is double precision supported on GPUs with 1.3 compute capability?: Yes -- double precision is supported for 1.3 and higher
15. What does compute capability mean?: Compute capability signifies the hardware version and supported features of a GPU